%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A template for Wiley article submissions.
% Developed by Overleaf. 
%
% Please note that whilst this template provides a 
% preview of the typeset manuscript for submission, it 
% will not necessarily be the final publication layout.
%
% Usage notes:
% The "blind" option will make anonymous all author, affiliation, correspondence and funding information.
% Use "num-refs" option for numerical citation and references style.
% Use "alpha-refs" option for author-year citation and references style.

% \documentclass[num-refs]{wiley-article}
\documentclass[num-refs]{mrm2plain}
% \documentclass[blind,alpha-refs]{wiley-article}

% added for highlighting
\usepackage{soul}

% added for margin notes
\usepackage{marginnote}

\bibliographystyle{vancouver-authoryear}

% Add additional packages here if required
\usepackage{siunitx}

% Graphics. Always show the figures but float to the end
% code listing
%\usepackage[final]{subfig, listings}
%\usepackage[nofiglist]{endfloat}

\graphicspath{{./figures/}}

% Update article type if known
\papertype{Full paper}
% Include section in journal if known, otherwise delete
% \paperfield{Journal Section}

\title{Adaptive Baseline Fitting for $^{\textbf{1}}$H MR Spectroscopy Analysis}

% Use the \authfn to add symbols for additional footnotes and present addresses, if any. Usually start with 1 for notes about author contributions; then continuing with 2 etc if any author has a different present address.
\author[1]{Martin Wilson}

%\contrib[\authfn{1}]{Equally contributing authors.}

% Include full affiliation details for all authors
\affil[1]{Centre for Human Brain Health and School of Psychology, University of Birmingham, Birmingham, UK.}

\corraddress{Martin Wilson, Centre for Human Brain Health, University of Birmingham, Edgbaston, Birmingham, B15 2TT, United Kingdom.}

\corremail{wilsonmp@bham.ac.uk}

% \fundinginfo{Funder One, Funder One Department, Grant/Award Number: 123456, 123457 and 123458; Funder Two, Funder Two Department, Grant/Award Number: 123459}

% Include the name of the author that should appear in the running header
\runningauthor{Wilson}

% my macros
\newcommand{\proton}{\ensuremath{^1\mathrm{H}}}
\newcommand{\bzero}{\ensuremath{\mathrm{B}_0}}
\soulregister\bzero7 % needed for soul to work with this macro
\soulregister\ref7 % needed for soul to work with this macro
\soulregister\cite7 % needed for soul to work with this macro

% revision two highlighting
%\newcommand{\revtwo}[2]{\hl{#1}\marginnote{\hl{#2}}}
%\newcommand{\revtwonm}[1]{\hl{#1}} % no margin label

% uncomment next two lines to hide revision two highlighting
%\newcommand{\revtwo}[2]{#1}
%\newcommand{\revtwonm}[1]{#1}

\begin{document}

\maketitle

\begin{abstract}
\textbf{Purpose:} \\
\textbf{Methods:} \\
\textbf{Results:} \\
\textbf{Conclusion:} 
\keywords{XXXX}
\end{abstract}

Word count : XXXX

% MRM abstract max length is 250 words
% MRM note max length is 2800 words, 5 fig plus tables

\section{Introduction}
A number of key metabolites may be detected using \proton\ Magnetic Resonance Spectroscopy (MRS), providing a non-invasive measure of healthy and diseased brain tissue metabolism. Clinical applications include the assessment of brain tumors, metabolic disorders and neonatal encephalopathy~\cite{Oz2014,Lally2019} where the concentration of certain metabolites may inform disease diagnosis or predict patient outcome. Further applications for MRS are present in the neuroscience and psychiatry domains, with particular interest in the direct detection of neurotransmitter levels such as GABA and glutamate, which have been shown to be abnormal in Schizophrenia~\cite{Merritt2016} and modulate in response to tasks~\cite{Jelen2018,Chen2017}.

MRS scans are typically performed at short (30ms) or long (144ms) TE's, with short-TE scans being preferred due to reduced T2 relaxation and dephasing of multiplets resulting in improved metabolite detection sensitivity~\cite{Wilson2019}. However, short-TE scans are typically more susceptible to artifacts originating from insufficient water and scalp lipid suppression, in addition, broad signals from macromolecules also become enhanced~\cite{Cudalbu2012}. Residual water signals, lipid signals and macromolecules all have the potential to bias metabolite measurements due to spectral overlap and interference. Therefore, appropriate analysis methodology is particularly important to achieve the full benefit of conventional short-TE MRS.

Parametric fitting is currently the most widely used analysis method for MRS data, and typically incorporates a set of simulated metabolite signals --- known as a basis set. One of the main distinctions between analysis methods is their approach for mitigating metabolite estimation bias from broad signals not present in the basis set, usually referred to as ``baseline modeling''. One of the most popular baseline modeling methods incorporates a set of smooth spline functions into the fitting procedure, with additional smoothness imposed by penalizing greater baseline complexity. The LCModel~\cite{Provencher1993} and AQSES~\cite{Poullet2007} algorithms both use penalized spline baseline modeling, with analysis performed in the frequency-domain and time-domain respectively.

An alternative approach to baseline modeling exploits the rapid decay of baseline signals in the time-domain by omitting the preliminary data points during the fitting process, reducing their interference with the more slowly decaying metabolites. The QUEST~\cite{Ratiney2005} and TARQUIN~\cite{Wilson2011} methods both use this time-domain truncation approach. The FITT~\cite{Young1998} algorithm combines the wavelet transform with Lowess filtering in the frequency-domain to separate metabolite and baseline signals.

Control over the level of baseline flexibility (or smoothness) is a common and necessary requirement of each of the baseline modeling methods outlined above. For spline based approaches, the number of spline functions for a given frequency range and the smoothness penalty parameter control the baseline flexibility. For LCModel, the frequency spacing between the spline basis functions is dependent on data quality, and is set at maximum of 1.5 times the estimated full width at half maximum (FWHM) of the metabolite resonances or 0.1 ppm~\cite{Provencher1993}. Similarly, for the FITT algorithm a fixed Lowess filter smoothing value is used and wavelet coefficients with scales less than twice the FWHM are excluded from the baseline model to ensure smoothness~\cite{Young1998}. In the time-domain truncation approach baseline flexibility is primarily determined by the number of initial data points to be omitted from the fit evaluation. For QUEST and TARQUIN the number of truncated data points, and therefore degree of baseline flexibility, is set at a default value that may be adjusted by the user.

Automated methods to determine the correct degree of baseline flexibility are important for obtaining accurate metabolite levels independently of the analyst. Furthermore, the manual adjustment of baseline flexibility for each individual spectrum is impractical for MRSI studies --- where hundreds of spectra may be acquired in a single scan. Whilst LCModel provides automated adjustment of baseline flexibility, a growing number of analysts choose to manually override the default analysis settings by adjusting the spline spacing parameter (DKNTMN). The first reported use of this manual adjustment was to improve the modeling of macromolecular resonances in rat brain at 9.4 T~\cite{Pfeuffer1999}. More recently, this parameter has been adjusted to encourage flatter baselines~\cite{Deelchand2016,Terpstra2010,Marjanska2018}, suggesting the default LCModel baseline flexibility may not be optimal in some cases.

Finding the optimal degree of baseline flexibility is a crucial question in MRS analysis research, yet few studies have investigated this topic in detail. Using simulated data, Ratiney et al.\ demonstrated how the interference between metabolite and baseline signals was reduced by increasing the number of omitted data points, but this came at the cost of inflating errors due to noise~\cite{Ratiney2004}. More recently, Near et al.\ showed how the estimated baseline in LCModel can depend strongly on spectral SNR and metabolite FWHM, and that errors caused by baseline instability may dominate over errors from spectral noise in some cases~\cite{Near2013}. The influence of baseline flexibility has also been explored using experimentally acquired data, with a recent study demonstrating a 15\% difference in metabolite levels when comparing between a default and less flexible baseline model~\cite{Giapitzakis2019}. Baseline flexibility has also been shown to have a strong influence of the measurement of 2-hydroxyglutarate~\cite{Wenger2019}.

In this study we introduce a new method to automatically determine the optimal degree of baseline flexibility for a frequency-domain spline based fitting algorithm. Firstly, background is given on the use of penalized splines for optimal data smoothing. A fully-automated fitting algorithm is presented, incorporating a novel method to automatically estimate the optimal level of baseline flexibility. Finally, the new method is validated on simulated and experimentally acquired MRSI data.

\section{Methods}
\subsection{Penalized spline regression}

Baseline signals have a characteristically smooth spectral appearance, and must to be accurately modeled to avoid biasing metabolite estimates. In good quality \proton\ MRS of brain tissue baseline signals have a low intensity, relative to the primary metabolite resonances, and are therefore challenging to estimate in the presence of noise. Estimating a smooth function from noisy data is known in statistics as ``scatterplot smoothing'', and a number of approaches have been developed~\cite{Ruppert2003}. In this section we briefly outline the method of penalized splines in the simpler context of scatterplot smoothing, before describing their use as part of an MRS fitting algorithm.

% Figure 1
\begin{figure}
  \begin{center}
    \includegraphics[width=1\textwidth]{fig1.pdf}
    \caption{xxx}
    \label{bspline_regression}
  \end{center}
\end{figure}

A spline is a piecewise function made up of one or more polynomial segments joined together at points known as ``knots''. A wide range of spline functions are possible, however Basis-splines, more commonly known as B-splines, are a popular choice for smoothing applications due to their favorable numerical properties~\cite{DeBoor2001}. The degree of a B-spline function determines its overall smoothness, and third degree (or cubic) B-splines are often used for smoothing. A cubic B-spline basis is show in Figure~\ref{bspline_regression}A with an offset added in the y-direction for clarity. B-spline bases consist of regularly spaced overlapping spline functions, spanning the full range of x values.

A B-spline basis may be used to obtain a smooth estimate of a signal using simple linear regression. Figure~\ref{bspline_regression}B shows the result of a spline regression, where each spline function has been optimally weighted, such that the sum of the functions (spline fit line) is the least squares fit to the data. The desired smoothness of the fit is controlled by adjusting the spline knot spacing, which in turn changes the density of spline functions. In the case of Figure~\ref{bspline_regression}B, 15 functions were found to give a reasonable level of smoothness. Increasing the density of spline functions allows more detail to be captured by the fit, however too many functions results in an increased sensitivity to noise and the smooth estimate begins to exhibit random fluctuations. Conversely, insufficient density of spline functions results in the spline fit being unable to model genuine smooth trends present in the data.

An alternative to adjusting the number of spline basis functions to achieve a desired level of smoothness is to introduce a penalty parameter into to spline regression model. The smooth estimate $\hat{y}$, of our data $y$, is calculated as: $\hat{y} = B \alpha$, where $B$ is a B-spline basis in matrix form, and $\alpha$ is the set of corresponding spline weightings to be determined. In simple spline regression $\alpha$ is found by solving the normal equations to minimize the sum of the square differences between $y$ and $\hat{y}$. In penalized spline regression, the minimization function $Q_B$ is adjusted to incorporate an additional term to enforce smoothness in the estimate:

\begin{equation}
  Q_{B} = ||y - B \alpha ||^{2} + \lambda ||D \alpha ||^{2}.
  \label{qb}
\end{equation}

The $\lambda$ parameter controls the degree of smoothness by penalizing solutions for $\alpha$ that interact with the difference matrix $D$. The difference matrix may be constructed to penalize the first, second or higher orders of differences between the $\alpha$ values. Here, we exclusively use a second order difference matrix, which acts to minimize the second derivative of the smooth estimate.

\begin{equation}
  D =
  \begin{bmatrix*}[r]
    1 & -2 &  1 &  0 &  0 &  0 & \dots \\
    0 &  1 & -2 &  1 &  0 &  0 & \dots \\
    0 &  0 &  1 & -2 &  1 &  0 & \dots \\
    0 &  0 &  0 &  1 & -2 &  1 & \dots \\
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
  \end{bmatrix*}
  \label{d_mat}
\end{equation}

An example of the second order difference matrix is given in~(\ref{d_mat}), which shows how increased differences between adjacent weighting factors in $\alpha$ consequently increase the penalty term in equation~(\ref{qb}). The minimization function $Q_{B}$ represents a compromise between minimizing the fit residual and smoothness, where a value of zero for $\lambda$ results in simple spline regression. Larger values of $\lambda$ encourage a smoother $\hat{y}$, to the point where $\hat{y}$ becomes a straight line fit for very large penalties when using a second order difference matrix. The solution to equation~(\ref{qb}) may be found by augmenting $B$ and $y$:

\begin{equation}
  \begin{bmatrix}
    y \\ 0
  \end{bmatrix}
  \approx
  \begin{bmatrix}
    B \\ \sqrt{\lambda} D
  \end{bmatrix},
\end{equation}

and regressing the augmented $y$ vector on the augmented $B$ matrix to yield $\alpha$.

The general approach for penalized spline regression is to over-specify the number of B-spline basis functions, and primarily control the smoothness through the adjustment of $\lambda$ acting on a difference matrix. We refer to this approach as ``P-splines'', first introduced by Eilers and Marx~\cite{Eilers1996}. Whilst the value of $\lambda$ has a direct effect on smoothness, it is an unintuitive parameter to interpret as the optimal value often varies by several orders of magnitude. In addition, $\lambda$ has a complex dependence on the density of the spline functions, the number of data points and other factors unrelated to smoothness. A more intuitive measure of the smoothness of a P-spline model is known as the effective dimension (ED), proposed by Hastie and Tibshirani \cite{Hastie1990}. For a given value of $\lambda$, B-spline basis $B$ and difference matrix $D$, we calculate ED as follows:

\begin{equation}
  H =
  \begin{bmatrix}
    B \\ \sqrt{\lambda} D
  \end{bmatrix}^{-1}
  \begin{bmatrix}
    B \\ 0
  \end{bmatrix},
\end{equation}

\begin{equation}
  \textrm{ED} = \mathrm{tr}(H),
\end{equation}

where $H$ is commonly known as the ``hat'' matrix. For a small value of $\lambda$, ED approaches the number of spline functions in the basis $B$, and for large values, ED approaches 2 when using a second order difference matrix.

% Figure 2
\begin{figure}
  \begin{center}
    \includegraphics[width=0.9\textwidth]{fig2.pdf}
    \caption{xxx}
    \label{pspline_error}
  \end{center}
\end{figure}

Using simulated data we can investigate the relationship between $\lambda$, ED and the optimal level of smoothness. The top left panel in Figure \ref{pspline_error}A shows a simple sine function with added normally distributed noise, shown in red and black respectively. Candidate P-spline smoothers, with differing values of $\lambda$, are shown in the remaining 5 panels. Since the true shape of the underlying smooth function is known, the error of the P-spline estimate may be calculated and plotted as a function of $\lambda$, shown in the lower panel of Figure \ref{pspline_error}B. The difference between the P-spline estimate and noisy data (residual) and the ED are also shown as a function of $\lambda$ in part B.

% note that error is RSS - is it? what about residual?

Inspection of the error plot reveals the optimal $\lambda$ to be approximately 20 --- corresponding to an ED value of 12, and this can be intuitively verified from part A. For larger values of $\lambda$, the estimate approaches a straight line fit --- failing to capture the details in the sine cure and resulting in an increasing fit residual and fit error (part B). Models with insufficient freedom to adapt to genuine trends in the data result in biased estimates and this is known as ``underfitting''. Conversely, too much freedom in the smoothing model (small $\lambda$) results in the estimate becoming overly sensitive to random fluctuations in the data resulting in ``overfitting''. In least-squares fitting, there is a temptation to equate the smallest residual with the optimal fit, however Figure \ref{pspline_error}B clearly shows an increase in the error for $\lambda$ values of less than 20 --- despite a steady reduction in the residual.

Determining the optimal value for the smoothness parameter is one of the primary challenges for P-spline smoothing. A careful balance between instability from overfitting, and bias from underfitting, must be struck for the most accurate estimate, and searching for the smallest fit residual is a useful, but insufficient metric of quality. Numerous approaches have been developed to find the optimal smoothing value \cite{Ruppert2003} and in this study we use an iterative method described by Eilers and Marx \cite{Eilers2010}. In short, the approach finds a $\lambda$ value which balances the variance of residual against the variance of the penalty term $D \alpha$.

\subsection{Adaptive Baseline Fitting}

\begin{enumerate}
  \item Convolution based frequency alignment.
  \item Approximate iterative fitting.
  \item Baseline smoothness estimation.
  \item Detailed iterative fitting.
\end{enumerate}

\section{Results}
XXXX

\section{Discussion}
MRM open science paper: https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.27939

\cite{Stikov2019}

% compare with LCModel P-spline approach which is more like O'Sullivan1986.

\cite{OSullivan1986}

\section{Conclusion}
XXXX

\section*{ACKNOWLEDGEMENTS}
XXXX

\bibliography{main}

\clearpage
\listoffigures

\end{document}

%%% Local Variables:
%%% ispell-local-dictionary: "american"
%%% End:

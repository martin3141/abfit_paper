# try this if you're getting compilation errors:
# for dir in "$HOME/.emacs.d/elpa/org-"*/; do find $dir -name "*.elc" -delete; done

#+TITLE: Adaptive Baseline Fitting for @@latex:\\@@ \(^1\)H MR Spectroscopy Analysis
#+AUTHOR: Martin Wilson
#+OPTIONS: toc:nil num:nil date:nil

# TODO ref shen paper - only validated on smaller baseline artefacts, not large outer-vol lipids

\begin{abstract}
This is the abstract.
\end{abstract}

* Introduction

  A number of key metabolites may be detected using \(^1\)H Magnetic Resonance Spectroscopy (MRS), providing a non-invasive measure of healthy and diseased brain tissue metabolism. Clinical applications include the assessment of brain tumours, metabolic disorders and neonatal encephalopathy cite:Oz2014,Lally2019 where the concentration of certain metabolites may inform disease diagnosis or predict patient outcome. Further applications for MRS are present in the neuroscience and psychiatry domains, with particular interest in the direct detection of neurotransmitter levels such as GABA and glutamate, which have been shown to be abnormal in Schizophrenia cite:Merritt2016 and modulate in response to tasks cite:Jelen2018,Chen2017.

  MRS scans are typically performed at short (30ms) or long (144ms) TE's, with short-TE scans being preferred due to reduced T2 relaxation and dephasing of multiplets resulting in improved metabolite detection sensitivity cite:Wilson2019. However, short-TE scans are typically more susceptible to artefacts originating from insufficient water and scalp lipid suppression, in addition, broad signals from macromolecules also become enhanced cite:Cudalbu2012. Residual water signals, lipid signals and macromolecules all have the potential to bias metabolite measurements due to spectral overlap and interference. Therefore, appropriate analysis methodology is particularly important to achieve the full benefit of conventional short-TE MRS.

  Parametric fitting is currently the most widely used analysis method for MRS data, and typically incorporates a set of simulated metabolite signals - known as a basis set. One of the main distinctions between analysis methods is their approach for mitigating metabolite estimation bias from broad signals not present in the basis set, usually referred to as "baseline modelling". One of the most popular baseline modelling methods incorporates a set of smooth spline functions into the fitting procedure, with additional smoothness imposed by penalising greater baseline complexity. The LCModel cite:Provencher1993 and AQSES cite:Poullet2007 algorithms both use penalised spline baseline modelling, with analysis performed in the frequency-domain and time-domain respectively. 

  An alternative approach to baseline modelling exploits the rapid decay of baseline signals in the time-domain by omitting the preliminary data points during the fitting process, reducing their interference with the more slowly decaying metabolites. The QUEST cite:Ratiney2005 and TARQUIN cite:Wilson2011 methods both use this time-domain truncation approach. The FITT cite:Young1998 algorithm combines the wavelet transform with Lowess filtering in the frequency-domain to separate metabolite and baseline signals.

  The specification of a maximum level of baseline flexibility is a common and necessary requirement of each of the baseline modelling methods outlined above. For spline based approaches, the number of spline functions for a given frequency range and the smoothness penalty parameter control the baseline flexibility. For LCModel, the frequency spacing between the spline basis functions is dependant on data quality, and is set at maximum of 1.5 times the estimated full width at half maximum (FWHM) of the metabolite resonances or 0.1 ppm cite:Provencher1993. Similarly, for the FITT algorithm a fixed Lowess filter smoothing value is used and wavelet coefficients with scales less than twice the FWHM are excluded from the baseline model to ensure smoothness cite:Young1998. In the time-domain truncation approach baseline flexibility is primarily determined by the number of initial data points to be omitted from the fit evaluation. For QUEST and TARQUIN the number of truncated data points, and therefore degree of baseline flexibility, is set at a default value that may be adjusted by the user. 

  Automated methods to determine the correct degree of baseline flexibility are important for obtaining accurate metabolite levels independently of the analyst. Furthermore, the manual adjustment of baseline flexibility for each individual spectrum is impractical for MRSI studies - where hundreds of spectra may be acquired in a single scan. Whilst LCModel provides automated adjustment of baseline flexibility, a growing number of analysts choose to manually override the default analysis settings by adjusting the spline spacing parameter (DKNTMN). The first reported use of this manual adjustment was to improve the modelling of macromolecular resonances in rat brain at 9.4 T cite:Pfeuffer1999. More recently, this parameter has been adjusted to encourage flatter baselines cite:Deelchand2016,Terpstra2010,Marjanska2018, suggesting the default LCModel baseline flexibility may not be optimal in some cases. 

  Finding the optimal degree of baseline flexibility is a crucial question in MRS analysis research, yet few studies have investigated this topic in detail. Using simulated data, Ratiney et al. demonstrated how the interference between metabolite and baseline signals was reduced by increasing the number of omitted data points, but this came at the cost of inflating errors due to noise cite:Ratiney2004. More recently, Near et al. showed how the estimated baseline in LCModel can depend strongly on spectral SNR and metabolite FWHM, and that errors caused by baseline instability may dominate over errors from spectral noise in some cases cite:Near2013. The influence of baseline flexibility has also been explored using experimentally acquired data, with a recent study demonstrating a 15% difference in metabolite levels when comparing between a default and less flexible baseline model cite:Giapitzakis2019. Baseline flexibility has also been shown to have a strong influence of the measurement of 2-hydroxyglutarate cite:Wenger2019.

  The purpose of this study is to develop a method to automatically determine the optimal degree of baseline flexibility for a frequency-domain spline based fitting algorithm. Firstly, simulated data is used to demonstrate how the fit residual reduces with decreasing baseline flexibility with a characteristic curve. The introduction of a broad baseline signal, not present in the basis set, significantly alters this curve - and a simple method is introduced to find the optimal degree of baseline flexibility. Finally, a fully automated fitting method, incorporating adaptive baseline flexibility, is described and tested using MRSI data acquired at 3T.

* Methods
** Penalised spline baseline modelling
   To highlight the key aspects of spline baseline modelling we first introduce our assumed MRS signal model in the frequency domain:

   \begin{equation}
   Y(\nu_k) = x(\nu_k) + b(\nu_k) + \epsilon(\nu_k)
   \end{equation}

where $x(\nu_k)$ represents data points arising from the set of signals we expect to be present in the acquired data, with each having an assumed spectral pattern. These signals are typically metabolite, lipid and macromolecular resonances

cite:Eilers2010



, $b(\nu_k)$, and $\epsilon(\nu_k)$ represent data points from 

   The primary distinguishing feature of the baseline contribution to the MRS signal is smoothness relative to the metabolite signals and noise distortions. Assuming the metabolite signals
   
   # simple non-iterative fitting model (projection only)
   - VARPRO + spline baseline
   \begin{equation}
   \sum_{k=1}^{N} \{\operatorname{Re}[Y(\nu_k) - \hat{Y}(\nu_k)]\}^2
   \end{equation}
   \begin{equation}
   \min_{x,a} \lVert \textbf{y} - \varPhi(\textbf{x})\textbf{a} \rVert_2^2
   \end{equation}
   Methods go here $y = mx + c$.
   - bl_fwhm scaling
** Residual as a function of bl_fwhm scaling
** Auto bl_fwhm method for the simple model case
** Full fitting algo inc. lineshape term for real data with bl_fwhm
** MRSI method validation (MW/GM correlation), echo-time bl_fwhm dependence?
* Results (real MRSI data)
  Awesome results.

#+ATTR_ORG: :width 600
#+CAPTION: This is the caption for the figure.
#+NAME: fig:somethinga
[[./images/example.jpg]]


#+CAPTION: This is the caption for the table.
#+NAME: tab:somethingb
| col 1 | col 2 | col 3 |
|-------+-------+-------|
| a     | b     | c     |
| a     | b     | c     |
| a     | b     | c     |
| a     | b     | c     |

This text references Table [[tab:somethingb]] and Figure [[fig:somethinga]].

* Discussion

Why penalised splines over TD or wavelets?

MRM open science paper: https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.27939

Can we correctly compare two spectra with vastly different baseline models in a bias free way?

Alternative could be to determine the bl_flex using the proposed method and omit spectra on this (or some other) basis and keep a fixed baseline flex.

Alternatives, HSVD water/lipid removal, or L1 preprocessing methods.

Amplitude of baseline component useful for QA?

Limitations - most voxels had very good linewidths

** Useful for QA
** How is this different to the LCModel approach? (hint, we don't care about linewidth here and we keep the number of "knots" fixed)
** limitations
*** slower (but could be easily parallelised for clinical applications)
*** only tested on simulated and healthy brain 1H data

bibliographystyle:ieeetr
bibliography:main.bib
